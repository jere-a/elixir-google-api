# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# NOTE: This file is auto generated by the elixir code generator program.
# Do not edit this file manually.

defmodule GoogleApi.ContentWarehouse.V1.Model.ImageSafesearchContentBrainPornAnnotation do
  @moduledoc """
  Don't change the field names. The names are used as sparse feature labels in client projects.

  ## Attributes

  *   `childScore` (*type:* `number()`, *default:* `nil`) - The probability that the youngest person in the image is a child.
  *   `csaiScore` (*type:* `float()`, *default:* `nil`) - This score correlates with potential child abuse. Google confidential!
  *   `csamA1Score` (*type:* `number()`, *default:* `nil`) - Experimental score. Do not use. Google confidential!
  *   `csamAgeIndeterminateScore` (*type:* `number()`, *default:* `nil`) - Experimental score. Do not use. Google confidential!
  *   `iuInappropriateScore` (*type:* `number()`, *default:* `nil`) - This field contains the probability that an image is inappropriate for Images Universal, according to this policy: go/iupolicy.
  *   `medicalScore` (*type:* `number()`, *default:* `nil`) - 
  *   `pedoScore` (*type:* `number()`, *default:* `nil`) - 
  *   `pornScore` (*type:* `float()`, *default:* `nil`) - 
  *   `racyScore` (*type:* `number()`, *default:* `nil`) - This score is related to an image being sexually suggestive.
  *   `semanticSexualizationScore` (*type:* `number()`, *default:* `nil`) - This score is related to racy/sexual images where scores have semantic meaning from 0 to 1.
  *   `spoofScore` (*type:* `number()`, *default:* `nil`) - 
  *   `version` (*type:* `String.t`, *default:* `nil`) - 
  *   `violenceScore` (*type:* `number()`, *default:* `nil`) - 
  *   `ytPornScore` (*type:* `number()`, *default:* `nil`) - Deprecated, use porn_score instead. The most recent model version does not produce this anymore.
  """

  use GoogleApi.Gax.ModelBase

  @type t :: %__MODULE__{
          :childScore => number() | nil,
          :csaiScore => float() | nil,
          :csamA1Score => number() | nil,
          :csamAgeIndeterminateScore => number() | nil,
          :iuInappropriateScore => number() | nil,
          :medicalScore => number() | nil,
          :pedoScore => number() | nil,
          :pornScore => float() | nil,
          :racyScore => number() | nil,
          :semanticSexualizationScore => number() | nil,
          :spoofScore => number() | nil,
          :version => String.t() | nil,
          :violenceScore => number() | nil,
          :ytPornScore => number() | nil
        }

  field(:childScore)
  field(:csaiScore)
  field(:csamA1Score)
  field(:csamAgeIndeterminateScore)
  field(:iuInappropriateScore)
  field(:medicalScore)
  field(:pedoScore)
  field(:pornScore)
  field(:racyScore)
  field(:semanticSexualizationScore)
  field(:spoofScore)
  field(:version)
  field(:violenceScore)
  field(:ytPornScore)
end

defimpl Poison.Decoder,
  for: GoogleApi.ContentWarehouse.V1.Model.ImageSafesearchContentBrainPornAnnotation do
  def decode(value, options) do
    GoogleApi.ContentWarehouse.V1.Model.ImageSafesearchContentBrainPornAnnotation.decode(
      value,
      options
    )
  end
end

defimpl Poison.Encoder,
  for: GoogleApi.ContentWarehouse.V1.Model.ImageSafesearchContentBrainPornAnnotation do
  def encode(value, options) do
    GoogleApi.Gax.ModelBase.encode(value, options)
  end
end
